{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8843e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9927e849",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/\"\n",
    "SEMANTICS_PATH = os.path.join(DATA_PATH, \"data_semantics\")\n",
    "TRAIN_PATH = os.path.join(SEMANTICS_PATH, \"training\")\n",
    "TRAIN_RGB_PATH = os.path.join(TRAIN_PATH, \"image_2\")\n",
    "TRAIN_SEMANTIC_PATH = os.path.join(TRAIN_PATH, \"semantic\")\n",
    "\n",
    "# rgbs = os.listdir(TRAIN_RGB_PATH)\n",
    "# semantics = os.listdir(TRAIN_SEMANTIC_PATH)\n",
    "\n",
    "# x = cv2.imread(os.path.join(TRAIN_RGB_PATH, rgbs[0]))\n",
    "# plt.figure()\n",
    "# plt.imshow(x)\n",
    "# print(x.shape)\n",
    "\n",
    "# x = cv2.imread(os.path.join(TRAIN_SEMANTIC_PATH, semantics[0]))\n",
    "# plt.figure()\n",
    "# plt.imshow(x)\n",
    "# print(x.shape)\n",
    "\n",
    "# for i in range(60):\n",
    "#     x = cv2.imread(os.path.join(TRAIN_SEMANTIC_PATH, semantics[i]))\n",
    "#     print(np.unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae94df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KITTI_SEG(Dataset):\n",
    "    def __init__(self, rgb_path, label_path, transform=transforms.Compose([transforms.Resize( (120, 480) )]),\n",
    "                                             target_transform=transforms.Compose([transforms.Resize( (120, 480) )]),\n",
    "                                             device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        self.rgb_path = rgb_path\n",
    "        self.rgb_names = os.listdir(self.rgb_path)         \n",
    "        \n",
    "        self.label_path = label_path\n",
    "        self.label_names = os.listdir(self.label_path)\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rgb_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.rgb_path, self.rgb_names[idx])\n",
    "        semantic_path = os.path.join(self.label_path, self.label_names[idx])        \n",
    "        \n",
    "        img = read_image(img_path).to(torch.float32)\n",
    "        label = read_image(semantic_path, ImageReadMode.GRAY).to(torch.long)\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        label = label.squeeze(0)            \n",
    "            \n",
    "        return img.to(self.device), label.to(self.device)\n",
    "    \n",
    "    def example(self):\n",
    "        image, label = self.__getitem__(3)\n",
    "        image = image.permute(1, 2, 0).to(\"cpu\").to(torch.uint8)\n",
    "        label = label.to(\"cpu\")\n",
    "        print(image.shape)\n",
    "        print(label.shape)\n",
    "        print(torch.unique(label))\n",
    "        plt.figure()\n",
    "        plt.imshow(image)\n",
    "        plt.figure()\n",
    "        plt.imshow(label)        \n",
    "        \n",
    "        \n",
    "# dataset = KITTI_SEG(TRAIN_RGB_PATH, TRAIN_SEMANTIC_PATH)\n",
    "# dataset.example()\n",
    "# dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "# for x, y in dataloader:\n",
    "#     print(x.shape)\n",
    "#     print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0dfa6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HorizontalBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(input_dim, output_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(output_dim, output_dim, kernel_size=3, padding=1)\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "        self.bn = nn.BatchNorm2d(output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.max_pool = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.max_pool(x)\n",
    "    \n",
    "class UpBlock(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()        \n",
    "        self.tconv = nn.ConvTranspose2d(input_dim, input_dim//2, kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.tconv(x)\n",
    "        return x\n",
    "    \n",
    "class ContractPath(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()        \n",
    "        self.hb1 = HorizontalBlock(input_dim, 64)\n",
    "        self.hb2 = HorizontalBlock(64, 128)\n",
    "        self.hb3 = HorizontalBlock(128, 256)\n",
    "        self.hb4 = HorizontalBlock(256, 512) \n",
    "        self.hb5 = HorizontalBlock(512,1024)         \n",
    "        \n",
    "        self.db = DownBlock()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.hb1(x)\n",
    "        x1c = self.db(x1)\n",
    "        \n",
    "        x2 = self.hb2(x1c)\n",
    "        x2c = self.db(x2)\n",
    "        \n",
    "        x3 = self.hb3(x2c)\n",
    "        x3c = self.db(x3)\n",
    "        \n",
    "        x4 = self.hb4(x3c)\n",
    "        x4c = self.db(x4) \n",
    "        \n",
    "        x5 = self.hb5(x4c)\n",
    "        return x5, x4, x3, x2, x1\n",
    "    \n",
    "class ExpandPath(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()        \n",
    "        self.hb1 = HorizontalBlock(1024, 512)        \n",
    "        self.hb2 = HorizontalBlock(512, 256)\n",
    "        self.hb3 = HorizontalBlock(256, 128)\n",
    "        self.hb4 = HorizontalBlock(128, 64)\n",
    "        self.out_conv = nn.Conv2d(64, output_dim, kernel_size=1)\n",
    "        \n",
    "        self.ub1 = UpBlock(1024)\n",
    "        self.ub2 = UpBlock(512)\n",
    "        self.ub3 = UpBlock(256)\n",
    "        self.ub4 = UpBlock(128)\n",
    "        \n",
    "    def forward(self, cp):\n",
    "        x = cp[0]\n",
    "        x = self.ub1(x) #512\n",
    "        \n",
    "        x_padded = torch.zeros(*cp[1].shape, device=x.device)\n",
    "        x_padded[:,:,:x.shape[2],:x.shape[3]] = x\n",
    "        x = torch.cat((x_padded, cp[1]), 1) #1024\n",
    "        x = self.hb1(x) #512\n",
    "        x = self.ub2(x) #256\n",
    "        \n",
    "        x = torch.cat((x, cp[2]), 1) #512\n",
    "        x = self.hb2(x) #256\n",
    "        x = self.ub3(x) #128\n",
    "\n",
    "        x = torch.cat((x, cp[3]), 1) #256\n",
    "        x = self.hb3(x) #128\n",
    "        x = self.ub4(x) #64   \n",
    "\n",
    "        x = torch.cat((x, cp[4]), 1) #128\n",
    "        x = self.hb4(x) #64\n",
    "        \n",
    "        x = self.out_conv(x) #num class\n",
    "        \n",
    "        return x\n",
    "                    \n",
    "    \n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_dim, num_class):\n",
    "        super().__init__()                \n",
    "        self.cp = ContractPath(input_dim)\n",
    "        self.ep = ExpandPath(num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat_maps = self.cp(x)\n",
    "        y = self.ep(feat_maps)\n",
    "        return y\n",
    "        \n",
    "    \n",
    "# x = torch.randn(1, 3, 480, 360)\n",
    "# unet = UNet(3, 10)\n",
    "# y = unet(x)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e6b187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# y = torch.randint(33, (10, 480, 360))\n",
    "# x = torch.randn(10, 33, 480, 360)\n",
    "# print(x.shape, y.shape)\n",
    "# z = loss(x, y)\n",
    "# z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d46a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 takes 375.8235070705414\n",
      "epoch 0\n",
      "running loss 141.0226399898529\n",
      "batch 5\r"
     ]
    }
   ],
   "source": [
    "def train(model, dataloader, num_epoch=10):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        running_loss = 0        \n",
    "        tic = time.time()\n",
    "        for batch_idx, (imgs, labels) in enumerate(dataloader):\n",
    "            print(\"batch\", batch_idx, end='\\r')\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "            pred = model(imgs)\n",
    "            loss = loss_fn(pred, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()           \n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        toc = time.time()\n",
    "        print(\"epoch\", epoch, \"takes\", toc-tic)\n",
    "            \n",
    "        if epoch % 1 == 0:\n",
    "            print(\"epoch\", epoch)\n",
    "            print(\"running loss\", running_loss)\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")        \n",
    "device = torch.device(\"cpu\")        \n",
    "\n",
    "dataset = KITTI_SEG(TRAIN_RGB_PATH, TRAIN_SEMANTIC_PATH, device=device)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "unet = UNet(3, 34).to(device)\n",
    "\n",
    "train(unet, dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
